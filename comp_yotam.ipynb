{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d545203",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/dcor/niskhizov/AdversarialRendering/mitsuba/gsoup/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import numpy as np\n",
    "import cv2\n",
    "from gsoup.image import (\n",
    "    change_brightness,\n",
    "    add_alpha,\n",
    "    resize,\n",
    "    tonemap_reinhard,\n",
    "    linear_to_srgb,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mi.set_variant(\n",
    "    \"cuda_ad_rgb\"\n",
    "    # \"scalar_rgb\"\n",
    ")  # \"llvm_ad_rgb\", \"scalar_rgb\" # must set before defining the emitter\n",
    "\n",
    "\n",
    "patchs = glob.glob('/home/dcor/niskhizov/AdversarialRendering/botorch_snapshots/*patch*')\n",
    "\n",
    "cam_wh=(256, 256)\n",
    "cam_fov=45\n",
    "proj_wh=(256, 256)\n",
    "proj_fov=45\n",
    "ambient_color=list(np.array([0.1, 0.1, 0.1] )*10)\n",
    "proj_brightness = 30\n",
    "\n",
    "spp=256\n",
    "proj_response_mode = \"srgb\"\n",
    "\n",
    "import gsoup\n",
    "from gsoup.projector_plugin_mitsuba import ProjectorPy\n",
    "import mitsuba as mi\n",
    "mi.register_emitter(\"projector_py\", lambda props: ProjectorPy(props))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1805f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughness = list(range(0.1,0.8, 0.1))\n",
    "# metallics  = list(range(0, 1.0, 0.1))\n",
    "\n",
    "roughness = list(np.arange(0.1, 0.8, 0.1))\n",
    "\n",
    "metallics  = list(np.arange(0, 1.0, 0.1))\n",
    "\n",
    "\n",
    "def generate_random_scene():\n",
    "    \"\"\"\n",
    "    Generate a random scene dictionary for Mitsuba.\n",
    "    \"\"\"            \n",
    "    random_patch = np.random.choice(patchs)\n",
    "\n",
    "    roughnes =  np.random.choice(roughness)\n",
    "    metallic = np.random.choice(metallics)\n",
    "\n",
    "    proj_brightness = 5.0#np.random.uniform(1.0, 10.0)\n",
    "\n",
    "    ambient_color_scale = np.random.uniform(0.1, 1.0)\n",
    "\n",
    "    ambient_color=list(np.array([1.0,1.0,1.0] )*ambient_color_scale)\n",
    "\n",
    "    focus_distance = np.random.uniform(1.0, 20.0)\n",
    "\n",
    "    scene_dict = {\n",
    "\n",
    "                    \"type\": \"scene\",\n",
    "\n",
    "                    \"integrator\": {\n",
    "                        \"type\": \"path\",\n",
    "                        \"hide_emitters\": True,\n",
    "                        \"max_depth\": 6,\n",
    "                    },\n",
    "                    \"camera\": {\n",
    "                        \"type\": \"thinlens\",\n",
    "                        'aperture_radius': 0.02,  # control DoF (0.0 = pinhole)\n",
    "                        'focus_distance': focus_distance,  # meters to subject\n",
    "                        \"fov\": cam_fov,\n",
    "                        \n",
    "                        \"to_world\": mi.ScalarTransform4f().look_at(\n",
    "                            origin=[0.1, 0, 0.0],  # along +X axis\n",
    "                            target=[0, 0, 0],\n",
    "                            up=[0, 0, 1],  # Z-up\n",
    "                        ),\n",
    "                        \"film\": {\n",
    "                            \"type\": \"hdrfilm\",\n",
    "                            \"width\": cam_wh[0],\n",
    "                            \"height\": cam_wh[1],\n",
    "                            \"pixel_format\": \"rgba\",\n",
    "                            \"rfilter\": {\"type\": \"box\"},\n",
    "                        },\n",
    "                        \"sampler\": {\n",
    "                            \"type\": \"independent\",\n",
    "                            \"sample_count\": spp,  # number of samples per pixel\n",
    "                        },\n",
    "                    },\n",
    "\n",
    "                    \"wall3\": {\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"to_world\": mi.ScalarTransform4f()\n",
    "                        .translate([-2.0, 0.0, 0.0])\n",
    "                        .rotate([0, 1, 0], 90),\n",
    "                        \"bsdf\": \n",
    "                        {\n",
    "\n",
    "                        'type': 'principled',\n",
    "                        'base_color': {\n",
    "                            'type': 'bitmap',\n",
    "                            'filename': f'{random_patch}',\n",
    "\n",
    "                        },\n",
    "                        'roughness' : roughnes,\n",
    "                        'metallic': metallic,\n",
    "                        },\n",
    "                    },\n",
    "\n",
    "                    \"projector\": {\n",
    "                        \"type\": \"projector_py\",\n",
    "                        \"irradiance\": {\n",
    "                            # \"type\": \"ref\",\n",
    "                            # \"id\": \"proj_texture\",\n",
    "                            \"type\": \"bitmap\",\n",
    "                            'filename': '/home/dcor/niskhizov/AdversarialRendering/mitsuba/mat_data/WoodFloor064_1K/WoodFloor064_1K-JPG_Color.jpg',\n",
    "                            # \"raw\": True,  # assuming the image is in linear RGB\n",
    "                            'format' : 'variant'\n",
    "                        },\n",
    "                        \"scale\": proj_brightness,\n",
    "                        \"to_world\": mi.ScalarTransform4f().look_at(\n",
    "                            origin=[0.005, 0, 0],  # along +X axis\n",
    "                            target=[0, 0, 0],\n",
    "                            up=[0, 0, 1],  # Z-up\n",
    "                        ),\n",
    "                        \"fov\": proj_fov,\n",
    "                        \"response_mode\": proj_response_mode,\n",
    "                    },\n",
    "                    \n",
    "                    \"ambient\": {\n",
    "                        \"type\": \"constant\",\n",
    "                        \"radiance\": {\"type\": \"rgb\", \"value\": ambient_color},\n",
    "                    },\n",
    "                }\n",
    "    \n",
    "    return scene_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0bbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dr.wrap(source='torch', target='drjit')\n",
    "def render_texture2(params, proj_tex_grad):\n",
    "\n",
    "\n",
    "\n",
    "    params['projector.irradiance.data'] = proj_tex_grad \n",
    "    params.update()\n",
    "\n",
    "    raw_render = mi.render(scene, params)\n",
    "\n",
    "\n",
    "\n",
    "    return raw_render\n",
    "\n",
    "def render(params, proj_tex_grad):\n",
    "\n",
    "    raw_render = render_texture2(params,proj_tex_grad)\n",
    "\n",
    "\n",
    "    alpha = raw_render[:, :, -1:]\n",
    "    image = raw_render[:, :, :3]\n",
    "    # no_alpha_render = gsoup.alpha_compose(render)\n",
    "    image = tonemap_reinhard(image, exposure=1.0)\n",
    "    # image = linear_to_srgb(image)\n",
    "    final_image = add_alpha(image, alpha)\n",
    "\n",
    "    final_image = final_image.clamp(0, 1.0)\n",
    "\n",
    "    return final_image[:,:,:3]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc1d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9611adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# black rectangle with white square in the center of size t\n",
    "import copy \n",
    "\n",
    "scene_dict = generate_random_scene()\n",
    "scene = mi.load_dict(scene_dict)\n",
    "params = mi.traverse(scene)\n",
    "\n",
    "t = 50\n",
    "z = np.zeros((proj_wh[0], proj_wh[1], 3), dtype=np.float32)\n",
    "oz = render(params, z).cpu()\n",
    "anchor = np.zeros((proj_wh[0], proj_wh[1], 3), dtype=np.float32)\n",
    "anchor[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :] = 1\n",
    "anchor = anchor.astype(np.float32)\n",
    "o_orig = render(params, anchor).cpu()\n",
    "plt.imshow(o_orig)\n",
    "plt.show()\n",
    "o = copy.deepcopy(o_orig)\n",
    "o[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :] = oz[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :]\n",
    "\n",
    "diff = (o - oz)**2\n",
    "# create an heatmap of the difference and add a scale bar\n",
    "plt.imshow(diff, cmap='hot')    \n",
    "plt.colorbar()\n",
    "plt.title('Difference Heatmap')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(o)\n",
    "plt.show()\n",
    "plt.imshow(oz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# Define glow parameters\n",
    "glow_radius = 10  # Controls the spread of the glow\n",
    "glow_strength = 10  # Controls the intensity of the glow\n",
    "sigma = glow_radius / 6.0\n",
    "\n",
    "def create_gaussian_kernel_2d(kernel_size, sigma):\n",
    "    \"\"\"Create a 2D Gaussian kernel using PyTorch\"\"\"\n",
    "    coords = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2\n",
    "    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
    "    g = g / g.sum()\n",
    "    \n",
    "    # Create 2D kernel\n",
    "    kernel_2d = g.unsqueeze(0) * g.unsqueeze(1)\n",
    "    return kernel_2d.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def gaussian_glow(image, kernel_size = glow_radius):\n",
    "    \"\"\"Apply Gaussian blur using PyTorch convolution with groups (no for loops)\"\"\"\n",
    "    # Ensure kernel size is odd\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    \n",
    "    sigma = glow_radius / 6.0  # Adjust sigma based on radius\n",
    "    # Create Gaussian kernel\n",
    "    kernel = create_gaussian_kernel_2d(kernel_size, sigma)\n",
    "    \n",
    "    # Reshape image from (H, W, C) to (1, C, H, W) for conv2d\n",
    "    img_4d = image.permute(2, 0, 1).unsqueeze(0)  # (1, 3, H, W)\n",
    "    \n",
    "    # Repeat kernel for each channel: (3, 1, kernel_size, kernel_size)\n",
    "    kernel_3ch = kernel.repeat(3, 1, 1, 1)\n",
    "    \n",
    "    # Apply convolution with groups=3 (one kernel per channel)\n",
    "    padding = kernel_size // 2\n",
    "    blurred_4d = F.conv2d(img_4d, kernel_3ch, padding=padding, groups=3)\n",
    "    \n",
    "    # Convert back to (H, W, C) format\n",
    "    img_blurred = blurred_4d.squeeze(0).permute(1, 2, 0)\n",
    "\n",
    "    img_blended = image + img_blurred * glow_strength\n",
    "\n",
    "    \n",
    "    return img_blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# black rectangle with white square in the center of size t\n",
    "import copy \n",
    "\n",
    "\n",
    "\n",
    "anchor_b = gaussian_glow(torch.tensor(anchor)).numpy()\n",
    "anchor_b = anchor_b.astype(np.float32)\n",
    "o_orig = render(params, anchor_b).cpu()\n",
    "plt.imshow(o_orig)\n",
    "plt.show()\n",
    "o = copy.deepcopy(o_orig)\n",
    "o[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :] = oz[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :]\n",
    "\n",
    "diff = (o - oz)**2\n",
    "# create an heatmap of the difference and add a scale bar\n",
    "plt.imshow(diff, cmap='hot')    \n",
    "plt.colorbar()\n",
    "plt.title('Difference Heatmap')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(o)\n",
    "plt.show()\n",
    "plt.imshow(oz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(anchor).permute(2, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian_blur_torch(torch.from_numpy(anchor).permute(2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # black rectangle with white square in the center of size t\n",
    "# import copy \n",
    "\n",
    "# scene_dict = generate_random_scene()\n",
    "# scene = mi.load_dict(scene_dict)\n",
    "# params = mi.traverse(scene)\n",
    "\n",
    "# t = 50\n",
    "# z = np.zeros((proj_wh[0], proj_wh[1], 3), dtype=np.float32)\n",
    "# oz = render(params, z).cpu()\n",
    "# anchor = np.zeros((proj_wh[0], proj_wh[1], 3), dtype=np.float32)\n",
    "# anchor[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :] = 1\n",
    "# anchor = anchor.astype(np.float32)\n",
    "# # anchor_blured = gaussian_blur_torch(torch.from_numpy(anchor).permute(2, 0, 1), sigma=1.0).squeeze(0).permute(1, 2, 0).numpy()\n",
    "# anchor_blured = gaussian_blur_torch(torch.from_numpy(anchor))\n",
    "# o_orig = render(params, anchor_blured).cpu()\n",
    "# plt.imshow(o_orig)\n",
    "# plt.show()\n",
    "# o = copy.deepcopy(o_orig)\n",
    "# o[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :] = oz[proj_wh[0]//2-t:proj_wh[0]//2+t, proj_wh[1]//2-t:proj_wh[1]//2+t, :]\n",
    "\n",
    "# diff = (o - oz)**2\n",
    "# # create an heatmap of the difference and add a scale bar\n",
    "# plt.imshow(diff, cmap='hot')    \n",
    "# plt.colorbar()\n",
    "# plt.title('Difference Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(o)\n",
    "# plt.show()\n",
    "# plt.imshow(oz)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65390947",
   "metadata": {},
   "source": [
    "# comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3b58c",
   "metadata": {},
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dr.wrap(source='torch', target='drjit')\n",
    "def render_texture2(params, proj_tex_grad, scene):\n",
    "\n",
    "\n",
    "\n",
    "    params['projector.irradiance.data'] = proj_tex_grad \n",
    "    params.update()\n",
    "\n",
    "    raw_render = mi.render(scene, params)\n",
    "\n",
    "\n",
    "\n",
    "    return raw_render\n",
    "\n",
    "def render(params, proj_tex_grad, scene):\n",
    "\n",
    "    raw_render = render_texture2(params,proj_tex_grad, scene)\n",
    "\n",
    "\n",
    "    alpha = raw_render[:, :, -1:]\n",
    "    image = raw_render[:, :, :3]\n",
    "    # no_alpha_render = gsoup.alpha_compose(render)\n",
    "    image = tonemap_reinhard(image, exposure=1.0)\n",
    "    # image = linear_to_srgb(image)\n",
    "    final_image = add_alpha(image, alpha)\n",
    "\n",
    "    final_image = final_image.clamp(0, 1.0)\n",
    "\n",
    "    return final_image[:,:,:3]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scene(proj_wh, cam_wh):\n",
    "    \"\"\"\n",
    "    helper function creating a mitsuba scene with a projector-camera pair\n",
    "    \"\"\"\n",
    "    projector_scene = gsoup.ProjectorScene()\n",
    "    proj_cv_K = np.array(\n",
    "        [\n",
    "            [proj_wh[0], 0.0, proj_wh[0] / 2],\n",
    "            [0.0, proj_wh[1], proj_wh[1] / 2],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ]\n",
    "    )\n",
    "    cam_cv_K = np.array(\n",
    "        [\n",
    "            [cam_wh[0], 0.0, cam_wh[0] / 2],\n",
    "            [0.0, cam_wh[1], cam_wh[1] / 2],\n",
    "            [0.0, 0.0, 1.0],\n",
    "        ]\n",
    "    )\n",
    "    projector_scene.create_default_scene(\n",
    "        proj_wh=proj_wh,\n",
    "        cam_wh=cam_wh,\n",
    "        cam_cv_K=cam_cv_K,\n",
    "        proj_cv_K=proj_cv_K,\n",
    "        # proj_fov=45.0,\n",
    "        # cam_fov=45.0,\n",
    "        proj_brightness=2.0,\n",
    "        spp=256,\n",
    "    )\n",
    "    transform = (\n",
    "        mi.ScalarTransform4f().look_at(\n",
    "            origin=[0.0, 0.0, 0.0],  # along +X axis\n",
    "            target=[-1, 0, 0],\n",
    "            up=[0, 0, 1],  # Z-up\n",
    "        ),\n",
    "    )\n",
    "    projector_scene.set_projector_transform(np.array(transform[0].matrix))\n",
    "    projector_scene.set_camera_transform(np.array(transform[0].matrix))\n",
    "    return projector_scene\n",
    "\n",
    "\n",
    "def simulate_procam(patterns_to_project, scene_dict, synth_V=None):\n",
    "    \"\"\"\n",
    "    helper function that simulates a video projector projecting some patterns onto a scene\n",
    "    :param patterns_to_project: a dictionary of numpy images to project\n",
    "    :param scene: a class containing a mitsuba scene (see procam.py)\n",
    "    :param synth_V: a synthetic color mixing matrix per-pixel, simulating real artifacts created by the projector\n",
    "    \"\"\"\n",
    "    captures = {}\n",
    "    ### simulate procam ###\n",
    "    for i, pattern_name in enumerate(sorted(patterns_to_project.keys())):\n",
    "        pattern = patterns_to_project[pattern_name]\n",
    "\n",
    "        scene = mi.load_dict(scene_dict)\n",
    "        params = mi.traverse(scene)\n",
    "        # scene.set_projector_texture(pattern)\n",
    "        # capture = scene.capture(raw=True)\n",
    "        capture = render(params, pattern, scene).cpu().numpy()\n",
    "        if synth_V is not None:\n",
    "            capture_expanded = capture[..., None]  # (H, W, 3, 1)\n",
    "            mixed = np.matmul(synth_V, capture_expanded)  # (H, W, 3, 1)\n",
    "            capture = capture_expanded[..., 0]  # remove singleton dimension â†’ (H, W, 3)\n",
    "        captures[pattern_name] = capture\n",
    "    ### end simulate procam ###\n",
    "    return captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_scene(proj_wh, cam_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Photometric Calibration Example\")\n",
    "proj_wh = (512, 512)\n",
    "cam_wh = (512, 512)\n",
    "low_val = 80 / 255\n",
    "high_val = 170 / 255\n",
    "n_samples_per_channel = 20\n",
    "################## offline steps for photometric calibration ##################\n",
    "# 0. create a scene\n",
    "scene_dict = generate_random_scene()#create_scene(proj_wh, cam_wh)\n",
    "# 1. create patterns for calibration\n",
    "# test_texture = gsoup.generate_voronoi_diagram(512, 512, 1000)\n",
    "# test_texture = gsoup.to_float(test_texture)\n",
    "patterns = {\n",
    "    # \"test_image\": test_texture,\n",
    "    \"all_black\": np.zeros(proj_wh + (3,), dtype=np.float32),\n",
    "    \"off_image\": np.ones(proj_wh + (3,), dtype=np.float32) * low_val,\n",
    "    \"red_image\": np.ones(proj_wh + (3,), dtype=np.float32) * low_val,\n",
    "    \"green_image\": np.ones(proj_wh + (3,), dtype=np.float32) * low_val,\n",
    "    \"blue_image\": np.ones(proj_wh + (3,), dtype=np.float32) * low_val,\n",
    "    \"on_image\": np.ones(proj_wh + (3,), dtype=np.float32) * high_val,\n",
    "    \"white_image\": np.ones(proj_wh + (3,), dtype=np.float32),\n",
    "}\n",
    "patterns[\"red_image\"][:, :, 0] = high_val\n",
    "patterns[\"green_image\"][:, :, 1] = high_val\n",
    "patterns[\"blue_image\"][:, :, 2] = high_val\n",
    "input_values = np.linspace(0.0, 1.0, num=20)\n",
    "for i in range(n_samples_per_channel):\n",
    "    patterns[\"gray_{:03d}\".format(i)] = (\n",
    "        np.ones(proj_wh + (3,), dtype=np.float32) * input_values[i]\n",
    "    )\n",
    "# 2. project patterns and acquire images (also simulate a global color mixing matrix)\n",
    "# synth_V = np.array([[0.9, 0.1, 0.1], [0.2, 0.8, 0.2], [0.1, 0.1, 0.9]])\n",
    "captured = simulate_procam(patterns, scene_dict, synth_V=None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for c in captured.keys():\n",
    "    plt.imshow(captured[c])\n",
    "    plt.title(c)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dee7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. we use a \"linear\" camera here, if not possible we need to find camera response function per channel\n",
    "# 4. and linearize camera response function\n",
    "# 5. no need to white balance camera channels, color mixing matrix will take care of that\n",
    "# 6. find inverse of color mixing matrix per-pixel\n",
    "inv_v = gsoup.procam.estimate_color_mixing_matrix(\n",
    "    off_image=captured[\"off_image\"],\n",
    "    red_image=captured[\"red_image\"],\n",
    "    green_image=captured[\"green_image\"],\n",
    "    blue_image=captured[\"blue_image\"],\n",
    "    cam_inv_response=None,\n",
    ")\n",
    "# 7. find projector inverse response function\n",
    "measured = np.stack(\n",
    "    [captured[\"gray_{:03d}\".format(i)] for i in range(n_samples_per_channel)],\n",
    "    axis=0,\n",
    ")\n",
    "proj_response = gsoup.procam.estimate_projector_inverse_response(\n",
    "    measured,\n",
    "    input_values=input_values,\n",
    "    fg_mask=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f69055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torchvision\n",
    "resizer = torchvision.transforms.Resize((512, 512))\n",
    "caltec_photos = '/home/dcor/niskhizov/caltech-101/101_ObjectCategories/'\n",
    "ls = glob.glob(caltec_photos + '/*/*.jpg')\n",
    "random_caltech_photo ='/home/dcor/niskhizov/caltech-101/101_ObjectCategories/bonsai/image_0098.jpg'# np.random.choice(ls)\n",
    "texture = cv2.cvtColor(cv2.imread(random_caltech_photo), cv2.COLOR_BGR2RGB)#gsoup.generate_voronoi_diagram(512, 512, 1000)*0+255\n",
    "proj_texture = gsoup.to_float(texture)\n",
    "proj_tex = torch.from_numpy(proj_texture).cuda() \n",
    "proj_tex_r = resizer(proj_tex.permute(2, 0, 1)) * 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ab184",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture = proj_tex_r.cpu().permute(1,2,0).numpy()#gsoup.generate_voronoi_diagram(512, 512, 1000)\n",
    "# reduce brightness for compensation to work\n",
    "texture_float = gsoup.to_float(texture) * 0.75\n",
    "# texture_float = np.ones((512, 512, 3), dtype=np.float32) * 0.5\n",
    "# 2. compute compensation image\n",
    "compensation_image = gsoup.procam.compute_compensation_image(\n",
    "    texture_float,\n",
    "    inv_v,\n",
    "    cam_inverse_response=None,\n",
    "    proj_inverse_response=proj_response,\n",
    ")\n",
    "# 3. project compensation image and uncompensated for comaprisons\n",
    "result = simulate_procam(\n",
    "    {\"compensation_image\": compensation_image, \"texture_float\": texture_float},\n",
    "    scene_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4224cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = mi.load_dict(scene_dict)\n",
    "params = mi.traverse(scene)\n",
    "o = render(params,texture, scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fe932",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(o.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dcor/niskhizov/AdversarialRendering/mitsuba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(texture_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fe947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result[\"compensation_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2cf33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result['texture_float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab275d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
